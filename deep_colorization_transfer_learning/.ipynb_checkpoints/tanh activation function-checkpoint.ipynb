{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from shutil import copy2\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from skimage.color import rgb2lab, rgb2gray, lab2rgb\n",
    "import re\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### converting the default data type to float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1 : Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of given list: 750\n",
      "number of images: 750\n",
      "Training Set Size: 675\n",
      "Testing Set Size: 75\n",
      "675\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"C:/Users/aashish/Desktop/DLCG2/face_images/\"\n",
    "files = glob.glob(\"C:/Users/aashish/Desktop/DLCG2/face_images/*.jpg\")\n",
    "\n",
    "\n",
    "print(\"Length of given list:\", len(files))\n",
    "train_data = \"C:/Users/aashish/Desktop/DLCG2/train/tensor/\"\n",
    "test_data = \"C:/Users/aashish/Desktop/DLCG2/test/tensor/\"\n",
    "\n",
    "os.makedirs(train_data, exist_ok = True)\n",
    "os.makedirs(test_data, exist_ok = True)\n",
    "\n",
    "num_images = len(next(os.walk(img_dir))[2])\n",
    "print(\"number of images:\", num_images)\n",
    "\n",
    "for i, file in enumerate(os.listdir(img_dir)):\n",
    "    if i < (0.1*num_images):\n",
    "        copy2(img_dir + file, test_data + file)\n",
    "        continue\n",
    "    else:\n",
    "        copy2(img_dir + file, train_data + file)\n",
    "\n",
    "print(\"Training Set Size:\", len(next(os.walk(train_data))[2]))\n",
    "print(\"Testing Set Size:\", len(next(os.walk(test_data))[2]))\n",
    "\n",
    "\n",
    "training_data = glob.glob('C:/Users/aashish/Desktop/DLCG2/train/tensor/*.jpg')\n",
    "testing_data = glob.glob('C:/Users/aashish/Desktop/DLCG2/test/tensor/*.jpg')\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(testing_data))\n",
    "# # for f1 in files:\n",
    "# #     img = cv.imread(f1)\n",
    "# #     img = cv.cvtColor(img, cv.COLOR_BGR2RGB) #converting to RGB\n",
    "# #     data.append(img)\n",
    "# # data_tensor = torch.tensor(data).permute(0,3,1,2) #Converting nparray to tensor and in desired order\n",
    "# # print (img.shape)\n",
    "# print (data_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class to return augmented datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedImageDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self,index):\n",
    "        global channel_a, channel_b, img_gray\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        original_image = np.asarray(img)\n",
    "        \n",
    "        img_lab = rgb2lab(original_image)\n",
    "        img_lab = img_lab + 128\n",
    "        img_lab = img_lab / 255\n",
    "        \n",
    "        channel_a = img_lab[:, :, 1:2]\n",
    "        channel_a = torch.from_numpy(channel_a.transpose((2,0,1))).float()\n",
    "        \n",
    "        channel_b = img_lab[:, :, 2:3]\n",
    "        channel_b = torch.from_numpy(channel_b.transpose((2,0,1))).float()\n",
    "        \n",
    "        img_gray = rgb2gray(original_image)\n",
    "        img_gray = torch.from_numpy(img_gray).unsqueeze(0).float()\n",
    "        \n",
    "        return channel_a, channel_b, img_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### augmenting the dataset and loading into 10* tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6750\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Resize(128),\n",
    "                               transforms.RandomHorizontalFlip(),\n",
    "                               transforms.RandomResizedCrop(128),\n",
    "#                                 transforms.ToTensor(), \n",
    "#                                        transforms.Normalize([0.6, 0.6, 0.6], [0.6, 0.6, 0.6])\n",
    "                               ])\n",
    "\n",
    "train_dataset =[]\n",
    "train_dataset.append(AugmentedImageDataset('C:/Users/aashish/Desktop/DLCG2/train'))\n",
    "for i in range(9):\n",
    "    train_dataset.append(AugmentedImageDataset('C:/Users/aashish/Desktop/DLCG2/train', transform))\n",
    "    \n",
    "augmented_dataset = ConcatDataset(train_dataset)\n",
    "print(len(augmented_dataset))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading all the data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = dict(shuffle = True, batch_size = 32)\n",
    "# if cuda:\n",
    "#     train_args = dict(shuffle = True, batch_size = 8, num_workers = 1, pin_memory = True)\n",
    "    \n",
    "augmented_batch_train = DataLoader(dataset = augmented_dataset, **train_args)\n",
    "augmented_batch_test = DataLoader(dataset = AugmentedImageDataset('C:/Users/aashish/Desktop/DLCG2/test')) \n",
    "#not applying transforms on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoking GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()else  \"cpu\")\n",
    "is_cuda_available = True if torch.cuda.is_available() else False\n",
    "if is_cuda_available:\n",
    "    num_workers = 8\n",
    "else:\n",
    "    num_workers = 0\n",
    "# print(device)\n",
    "print(format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building the Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self, in_channel=1, hidden_channel=3, out_dims=2, train_mode = \"regressor\"):\n",
    "        super(Regressor,self).__init__()\n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = in_channel, out_channels = 32, kernel_size=2, stride=2,padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=2, stride=2,padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size=2, stride=2,padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels =128, out_channels = 256, kernel_size=2, stride=2,padding=0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size=2, stride=2,padding=0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size=2, stride=2,padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        if self.train_mode == \"regressor\":\n",
    "            self.lin = nn.Linear(in_features=512 * 2 * 2, out_features=out_dims)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        if self.train_mode == \"regressor\":\n",
    "            y = torch.sigmoid(self.lin(features.reshape(-1,512*2*2)))\n",
    "            return y\n",
    "        else:\n",
    "            return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colorizer(nn.Module):\n",
    "    def __init__(self, in_channel=3, hidden_channel=3, out_channel=2,activation_function = \"sigmoid\"):\n",
    "        super(Colorizer, self).__init__()\n",
    "        self.activation_function = activation_function\n",
    "        self.features = Regressor(in_channel=1, hidden_channel = 3, out_dims=2, train_mode=\"colorizer\")\n",
    "        \n",
    "        self.up_sampling = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels = 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels = 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels = 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels = 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels = 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels = out_channel, kernel_size=4, stride=2, padding=1)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            return torch.sigmoid(self.up_sampling(self.features(x)))\n",
    "        elif self.activation_function == \"tanh\":\n",
    "            return torch.tanh(self.up_sampling(self.features(x)))\n",
    "        elif self.activation_function == \"relu\":\n",
    "            return torch.relu(self.up_sampling(self.features(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ab_mean(a_channel, b_channel):\n",
    "    a_channel_mean = a_channel.mean(dim = (2,3))\n",
    "    b_channel_mean = b_channel.mean(dim=(2,3))\n",
    "    a_b_mean = torch.cat([a_channel_mean,b_channel_mean], dim = 1)\n",
    "    \n",
    "    return a_b_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb(gray_input, ab_input, save_path = None, save_name = None, device = \"cpu\"):\n",
    "    plt.clf()\n",
    "    color_image = torch.cat((gray_input, ab_input), 0).numpy()\n",
    "    color_image = color_image.transpose((1,2,0))\n",
    "    \n",
    "    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n",
    "    color_image = lab2rgb(color_image.astype(np.float64))\n",
    "    gray_input = gray_input.squeeze().numpy()\n",
    "    if save_path is not None and save_name is not None:\n",
    "        plt.imsave(arr=gray_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap = 'gray')\n",
    "        plt.imsave(arr=color_image, fname = '{}{}'.format(save_path['colorized'], save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(gray, orig, new, fig_name):\n",
    "    plt.clf()\n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1, 3, 1)\n",
    "    plt.imshow(mpimg.imread(gray))\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(1, 3, 2)\n",
    "    plt.imshow(mpimg.imread(orig))\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(1, 3, 3)\n",
    "    plt.imshow(mpimg.imread(new))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.draw()\n",
    "    plt.savefig(fig_name, dpi=220)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping_DCN:\n",
    "    def __init__(self, patience = 7, verbose = False, delta = 0, model_path = None, trace_func = print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.model_path = model_path\n",
    "        self.trace_func = trace_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hyperparameters():\n",
    "    parameters = dict(lr=[0.001],\n",
    "                     weight_decay=[1e-5],\n",
    "                     epoch=[100])\n",
    "    hyperparam = [i for i in parameters.values()]\n",
    "    return hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reg:\n",
    "    def reg_train(self, augmented_dataset_batch, device):\n",
    "        print(\"...Regressor training Started...\")\n",
    "        model = Regressor(in_channel = 1, hidden_channel = 3, out_dims = 2, train_mode = \"regressor\").to(device)\n",
    "\n",
    "        lossF = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr = 0.0001, weight_decay = 1e-4)\n",
    "\n",
    "        loss_train = []\n",
    "\n",
    "        #start training\n",
    "        epochs = 100\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            model.train()\n",
    "\n",
    "            for batch in augmented_dataset_batch:\n",
    "                l_channel, a_channel, b_channel = batch\n",
    "                l_channel = l_channel.to(device)\n",
    "\n",
    "                a_b_mean = get_ab_mean(a_channel, b_channel)\n",
    "                a_b_mean_hat = model(l_channel)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    loss = lossF(a_b_mean_hat.float().cuda(),a_b_mean.float().cuda()).to(device)\n",
    "                else:\n",
    "                    loss = Lossf(a_b_mean_hat.float(), a_b_mean.float()).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(\"epoch: {0}, loss: {1}\".format(epoch, total_loss))\n",
    "            loss_train.append(total_loss)\n",
    "\n",
    "        # plotting loss/ epoch graph\n",
    "        plt.ion()\n",
    "        fig = plt.figure()\n",
    "        plt.plot(loss_train)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "        plt.draw()\n",
    "        plt.savefig('C:/Users/aashish/Desktop/DLCG2/Graphs', dpi = 200)\n",
    "        plt.clf()\n",
    "        torch.save(model.state_dict(), \"C:/Users/aashish/Desktop/DLCG2/Graphs/Reg.pth\")\n",
    "        \n",
    "    def reg_test(self, augmented_dataset_batch, device):\n",
    "        print(\"<<Regressor testing started>>\")\n",
    "        model = Regressor(in_channel= 1, hidden_channel=3, out_dims = 2, train_mode = \"regressor\").to(device)\n",
    "        model.load_state_dict(torch.load(\"C:/Users/aashish/Desktop/DLCG2/Graphs/Reg.pth\", map_location=device))\n",
    "        \n",
    "        a_list = []\n",
    "        b_list = []\n",
    "        lossF = nn.MSELoss()\n",
    "        total_loss = 0\n",
    "        loss_test = []\n",
    "        for batch in augmented_dataset_batch:\n",
    "            l_channel, a_channel, b_channel = batch\n",
    "            l_channel = l_channel.to(device)\n",
    "            \n",
    "            a_b_mean = get_ab_mean(a_channel, b_channel)\n",
    "            a_b_mean_hat = model(l_channel).detach()\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                loss = lossF(a_b_mean_hat.float().cuda(), a_b_mean.float().cuda()).to(device)\n",
    "            else:\n",
    "                loss = lossF(a_b_mean_hat.float(), a_b_mean.float()).to(device)\n",
    "            loss_test.append(loss.item())\n",
    "            \n",
    "            a_b_pred = a_b_mean_hat[0].cpu().numpy()\n",
    "            a_list.append(a_b_pred[0])\n",
    "            b_list.append(a_b_pred[1])\n",
    "        print(\"MSE:\", np.average(np.asarray(loss_test)))\n",
    "        print(\"Num_Image || Mean a || Mean b\")\n",
    "        for i in range(1, len(a_list)):\n",
    "            print(\"Image:{0} mean_a: {1} mean_b:{2}\".format(i, (a_list[i] * 255)-128, (b_list[i]*255)-128))\n",
    "            \n",
    "    def train_colorizer(self, augmented_dataset_batch, activation_function, model_name, device):\n",
    "        print(\"...Activation Function...\", activation_function)\n",
    "        print(\"...colorizer training started...\")\n",
    "        \n",
    "        \n",
    "        parameters = Hyperparameters()\n",
    "        for lr, weight_decay, epoch in product(*parameters):\n",
    "            print(\"Epoch: {0}, lr: {1}, weight decay:{2}\".format(epoch, lr, weight_decay))\n",
    "            model = Colorizer(in_channel=3, hidden_channel=3, activation_function = activation_function).to(device)\n",
    "        \n",
    "            lossF = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr =lr, weight_decay = weight_decay)\n",
    "#             saved_model_path = model_name.format(epoch, lr, weight_decay)\n",
    "            loss_train = []\n",
    "            early_stopping = EarlyStopping_DCN(patience = 50, verbose=True, model_path=\"C:/Users/aashish/Desktop/DLCG2/Graphs/color.pth\")\n",
    "#             epochs = 100\n",
    "            for epoch in range(epoch):\n",
    "                total_train_loss = 0\n",
    "                total_val_loss = 0\n",
    "                model.train()\n",
    "                \n",
    "                for batch in augmented_dataset_batch:\n",
    "                    channel_l, channel_a, channel_b = batch\n",
    "                    channel_l = channel_l.to(device)\n",
    "                    \n",
    "                    channel_a_b = torch.cat([channel_a, channel_b], dim = 1)\n",
    "                    channel_a_b_hat = model(channel_l)\n",
    "                    \n",
    "                    if torch.cuda.is_available():\n",
    "                        loss = lossF(channel_a_b_hat.float().cuda(), channel_a_b.float().cuda()).to(device)\n",
    "                    else:\n",
    "                        loss = lossF(channel_a_b_hat.float(), channel_a_b.float()).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_train_loss += loss.item()\n",
    "                    \n",
    "                print(\"epoch:{0}, loss:{1}\".format(epoch, total_train_loss))\n",
    "                loss_train.append(total_train_loss)\n",
    "                \n",
    "                \n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early Stop\")\n",
    "                    break\n",
    "                    \n",
    "                # plotting loss/ epoch graph\n",
    "            plt.ion()\n",
    "            fig = plt.figure()\n",
    "            plt.plot(loss_train)\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "            plt.draw()\n",
    "            plt.savefig('C:/Users/aashish/Desktop/DLCG2/Graphs/loss_plot_path.jpeg', dpi = 220)\n",
    "            plt.clf()\n",
    "            torch.save(model.state_dict(), \"C:/Users/aashish/Desktop/DLCG2/Graphs/color.pth\")\n",
    "        \n",
    "        \n",
    "    def test_colorizer(self, augmented_dataset_batch, activation_function, save_path, model_name, device):\n",
    "        parameters = Hyperparameters()\n",
    "        for lr, weight_decay, epoch in product(*parameters):\n",
    "#             print(\"------\")\n",
    "            print(\"Epoch : {0}, lr: {1}, Weight_decay: {2}\".format(epoch, lr, weight_decay))\n",
    "            \n",
    "#             saved_model_path = model_name.format(epoch, lr, weight_decay)\n",
    "                \n",
    "            print(activation_function)\n",
    "            print(\"--- Colorizer Testing Started ---\")\n",
    "            model = Colorizer(in_channel=3, hidden_channel = 3, activation_function = activation_function).to(device)\n",
    "            model.load_state_dict(torch.load(\"C:/Users/aashish/Desktop/DLCG2/Graphs/color.pth\", map_location = device))\n",
    "                \n",
    "            lossF = nn.MSELoss()\n",
    "            num = 0\n",
    "            for batch in augmented_dataset_batch:\n",
    "                num += 1\n",
    "                channel_l, channel_a, channel_b = batch\n",
    "                channel_l = channel_l.to(device)\n",
    "                    \n",
    "                channel_a_b = torch.cat([channel_a, channel_b], dim=1)\n",
    "                channel_a_b_hat = model(channel_l).detach()\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    loss = lossF(channel_a_b_hat.float().cuda(), channel_a_b.float().cuda()).to(device)\n",
    "                else:\n",
    "                    loss = lossF(channel_a_b_hat.float(), channel_a_b.float()).to(device)\n",
    "                    \n",
    "                print(\"Image: {0}, loss: {1}\".format(num, loss.item()))\n",
    "                \n",
    "                \n",
    "                save_original = 'Orig_img_epoch_{0}_lr_{1}_wt_decay_{2}_num_{3}.jpg' \\\n",
    "                    .format(epoch, lr, weight_decay, num)\n",
    "                save_new = 'new_img_epoch_{0}_lr_{1}_wt_decay_{2}_num_{3}.jpg' \\\n",
    "                    .format(epoch, lr, weight_decay, num)\n",
    "                \n",
    "                to_rgb(channel_l[0].cpu(), channel_a_b[0].cpu(),\n",
    "                    save_path = save_path, save_name = save_original, device = device)\n",
    "                to_rgb(channel_l[0].cpu(), channel_a_b[0].cpu(),\n",
    "                    save_path = save_path, save_name = save_new, device = device)\n",
    "                \n",
    "        self.display_imgs(epoch, lr, weight_decay, save_path)\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def display_imgs(epoch, lr, weight_decay, save_path):\n",
    "        color_path = save_path['colorized']\n",
    "        gray_path = save_path['grayscale']\n",
    "            \n",
    "            \n",
    "        for i in range(7,70,7):\n",
    "            title = \"\".\\\n",
    "                format(epoch, lr, weight_decay, i)\n",
    "            save_original = 'orig_img_epoch_{0}_lr_{1}_wt_decay_{2}_num_{3}.jpg' \\\n",
    "                   .format(epoch, lr, weight_decay, i)\n",
    "            save_new = 'new_img_epoch_{0}_lr_{1}_wt_decay_{2}_num_{3}.jpg' \\\n",
    "                    .format(epoch, lr, weight_decay, i)\n",
    "            display_image(gray_path + save_original, color_path + save_original, \n",
    "                              color_path + save_new, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Regressor training Started...\n",
      "epoch: 0, loss: 1.044610203942284\n",
      "epoch: 1, loss: 0.5405467122327536\n",
      "epoch: 2, loss: 0.44150946801528335\n",
      "epoch: 3, loss: 0.40842909179627895\n",
      "epoch: 4, loss: 0.3827952303690836\n",
      "epoch: 5, loss: 0.34980555856600404\n",
      "epoch: 6, loss: 0.3486472775693983\n",
      "epoch: 7, loss: 0.3224104598048143\n",
      "epoch: 8, loss: 0.3163411595742218\n",
      "epoch: 9, loss: 0.3252976141520776\n",
      "epoch: 10, loss: 0.31739011156605557\n",
      "epoch: 11, loss: 0.29596856608986855\n",
      "epoch: 12, loss: 0.2952006359118968\n",
      "epoch: 13, loss: 0.30234511487651616\n",
      "epoch: 14, loss: 0.2998834074824117\n",
      "epoch: 15, loss: 0.29119718488072976\n",
      "epoch: 16, loss: 0.2873685525264591\n",
      "epoch: 17, loss: 0.28098358382703736\n",
      "epoch: 18, loss: 0.287632352556102\n",
      "epoch: 19, loss: 0.28156063286587596\n",
      "epoch: 20, loss: 0.28758428629953414\n",
      "epoch: 21, loss: 0.28540613129734993\n",
      "epoch: 22, loss: 0.2723065981990658\n",
      "epoch: 23, loss: 0.27990309888264164\n",
      "epoch: 24, loss: 0.25366499336087145\n",
      "epoch: 25, loss: 0.27038505423115566\n",
      "epoch: 26, loss: 0.25565943121910095\n",
      "epoch: 27, loss: 0.2692833168548532\n",
      "epoch: 28, loss: 0.25777460663812235\n",
      "epoch: 29, loss: 0.2464966947445646\n",
      "epoch: 30, loss: 0.2746698812698014\n",
      "epoch: 31, loss: 0.2640369297005236\n",
      "epoch: 32, loss: 0.2591236066655256\n",
      "epoch: 33, loss: 0.26508430135436356\n",
      "epoch: 34, loss: 0.2625519955472555\n",
      "epoch: 35, loss: 0.24303908611182123\n",
      "epoch: 36, loss: 0.2482842348399572\n",
      "epoch: 37, loss: 0.24263229017378762\n",
      "epoch: 38, loss: 0.2506519705639221\n",
      "epoch: 39, loss: 0.2540784160955809\n",
      "epoch: 40, loss: 0.2325552040420007\n",
      "epoch: 41, loss: 0.24669274786720052\n",
      "epoch: 42, loss: 0.24415408133063465\n",
      "epoch: 43, loss: 0.23194044808042236\n",
      "epoch: 44, loss: 0.22436986461980268\n",
      "epoch: 45, loss: 0.22843489691149443\n",
      "epoch: 46, loss: 0.23556280639604665\n",
      "epoch: 47, loss: 0.2363063509692438\n",
      "epoch: 48, loss: 0.24244272941723466\n",
      "epoch: 49, loss: 0.23016115371137857\n",
      "epoch: 50, loss: 0.2238248377398122\n",
      "epoch: 51, loss: 0.2240012146648951\n",
      "epoch: 52, loss: 0.2394439717172645\n",
      "epoch: 53, loss: 0.21274137296131812\n",
      "epoch: 54, loss: 0.22109695454128087\n",
      "epoch: 55, loss: 0.21558748043025844\n",
      "epoch: 56, loss: 0.2184636076563038\n",
      "epoch: 57, loss: 0.2299214780505281\n",
      "epoch: 58, loss: 0.21768007564241998\n",
      "epoch: 59, loss: 0.21312188112642616\n",
      "epoch: 60, loss: 0.2171765342936851\n",
      "epoch: 61, loss: 0.21686422638595104\n",
      "epoch: 62, loss: 0.21904472177266143\n",
      "epoch: 63, loss: 0.21471657120855525\n",
      "epoch: 64, loss: 0.20972377268481068\n",
      "epoch: 65, loss: 0.21357123518828303\n",
      "epoch: 66, loss: 0.21448746891110204\n",
      "epoch: 67, loss: 0.20512730407062918\n",
      "epoch: 68, loss: 0.2246200778754428\n",
      "epoch: 69, loss: 0.2091983300051652\n",
      "epoch: 70, loss: 0.20229495427338406\n",
      "epoch: 71, loss: 0.20738859436823986\n",
      "epoch: 72, loss: 0.20974822057178244\n",
      "epoch: 73, loss: 0.21936861227732152\n",
      "epoch: 74, loss: 0.20610120965284295\n",
      "epoch: 75, loss: 0.2077654343447648\n",
      "epoch: 76, loss: 0.21084135712590069\n",
      "epoch: 77, loss: 0.1983917046454735\n",
      "epoch: 78, loss: 0.19921366186463274\n",
      "epoch: 79, loss: 0.19505475903861225\n",
      "epoch: 80, loss: 0.20034943224163726\n",
      "epoch: 81, loss: 0.19884023210033774\n",
      "epoch: 82, loss: 0.19926824508002028\n",
      "epoch: 83, loss: 0.19012417498743162\n",
      "epoch: 84, loss: 0.1942843772121705\n",
      "epoch: 85, loss: 0.20567419994040392\n",
      "epoch: 86, loss: 0.20125123992329463\n",
      "epoch: 87, loss: 0.19445181314949878\n",
      "epoch: 88, loss: 0.19108192977728322\n",
      "epoch: 89, loss: 0.18780371933826245\n",
      "epoch: 90, loss: 0.19375348801258951\n",
      "epoch: 91, loss: 0.18515572446631268\n",
      "epoch: 92, loss: 0.19628211003146134\n",
      "epoch: 93, loss: 0.20922999636968598\n",
      "epoch: 94, loss: 0.2010655029444024\n",
      "epoch: 95, loss: 0.18939470534678549\n",
      "epoch: 96, loss: 0.18458077029208653\n",
      "epoch: 97, loss: 0.1862063919834327\n",
      "epoch: 98, loss: 0.19267508439952508\n",
      "epoch: 99, loss: 0.18852248782059178\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Myregressor = Reg()\n",
    "Myregressor.reg_train(augmented_batch_train,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<Regressor testing started>>\n",
      "MSE: 0.0008871004179062683\n",
      "Num_Image || Mean a || Mean b\n",
      "Image:1 mean_a: 8.494998931884766 mean_b:-4.038932502269745\n",
      "Image:2 mean_a: 16.828316569328308 mean_b:-17.646040350198746\n",
      "Image:3 mean_a: 15.378800749778748 mean_b:-25.125954180955887\n",
      "Image:4 mean_a: 11.831387102603912 mean_b:-74.39364689588547\n",
      "Image:5 mean_a: 15.836539387702942 mean_b:-53.39335936307907\n",
      "Image:6 mean_a: 17.52214413881302 mean_b:-1.251432478427887\n",
      "Image:7 mean_a: 12.43164849281311 mean_b:-45.26705461740494\n",
      "Image:8 mean_a: 14.899585664272308 mean_b:-71.84683735668659\n",
      "Image:9 mean_a: 13.69106811285019 mean_b:-61.100493401288986\n",
      "Image:10 mean_a: 13.641275584697723 mean_b:-29.437385231256485\n",
      "Image:11 mean_a: 17.798510909080505 mean_b:-78.42313687503338\n",
      "Image:12 mean_a: 10.822161257266998 mean_b:-47.852762669324875\n",
      "Image:13 mean_a: 7.784877836704254 mean_b:-11.871186226606369\n",
      "Image:14 mean_a: 15.965595662593842 mean_b:-18.579209476709366\n",
      "Image:15 mean_a: 12.34615308046341 mean_b:-28.354716926813126\n",
      "Image:16 mean_a: 11.429429471492767 mean_b:-12.786169528961182\n",
      "Image:17 mean_a: 9.107860445976257 mean_b:-9.788875162601471\n",
      "Image:18 mean_a: 16.091004133224487 mean_b:-19.11457034945488\n",
      "Image:19 mean_a: 14.851601839065552 mean_b:9.727181613445282\n",
      "Image:20 mean_a: 16.98500496149063 mean_b:-41.84298235177994\n",
      "Image:21 mean_a: 11.916487336158752 mean_b:-50.036125510931015\n",
      "Image:22 mean_a: 14.772353291511536 mean_b:-29.21551513671875\n",
      "Image:23 mean_a: 14.751180827617645 mean_b:-30.33752653002739\n",
      "Image:24 mean_a: 15.499710261821747 mean_b:-40.608101814985275\n",
      "Image:25 mean_a: 11.368587136268616 mean_b:10.700066208839417\n",
      "Image:26 mean_a: 16.908355474472046 mean_b:-9.210196614265442\n",
      "Image:27 mean_a: 11.139687418937683 mean_b:-39.38604179024696\n",
      "Image:28 mean_a: 12.812631249427795 mean_b:-2.207301586866379\n",
      "Image:29 mean_a: 12.195529162883759 mean_b:-27.310016185045242\n",
      "Image:30 mean_a: 12.464539527893066 mean_b:-4.71048566699028\n",
      "Image:31 mean_a: 11.796428978443146 mean_b:-39.516747176647186\n",
      "Image:32 mean_a: 10.065135478973389 mean_b:-36.66538777947426\n",
      "Image:33 mean_a: 13.416479647159576 mean_b:-37.76565673947334\n",
      "Image:34 mean_a: 6.823894202709198 mean_b:-36.91421362757683\n",
      "Image:35 mean_a: 11.975201785564423 mean_b:-10.981593161821365\n",
      "Image:36 mean_a: 18.760680079460144 mean_b:-21.32665964961052\n",
      "Image:37 mean_a: 10.396675288677216 mean_b:-54.86380445957184\n",
      "Image:38 mean_a: 14.217719852924347 mean_b:-35.86618426442146\n",
      "Image:39 mean_a: 6.695810675621033 mean_b:-0.2427082061767578\n",
      "Image:40 mean_a: 14.703197002410889 mean_b:-37.716677367687225\n",
      "Image:41 mean_a: 11.601438641548157 mean_b:-32.65594932436943\n",
      "Image:42 mean_a: 14.82175064086914 mean_b:-29.97949454188347\n",
      "Image:43 mean_a: 13.62306696176529 mean_b:-14.474844515323639\n",
      "Image:44 mean_a: 10.9780592918396 mean_b:2.670625865459442\n",
      "Image:45 mean_a: 10.824030756950378 mean_b:-40.50807598233223\n",
      "Image:46 mean_a: 8.76390290260315 mean_b:-27.582583159208298\n",
      "Image:47 mean_a: 5.896637558937073 mean_b:-39.97629451751709\n",
      "Image:48 mean_a: 13.106948256492615 mean_b:-41.24651315808296\n",
      "Image:49 mean_a: 11.941702783107758 mean_b:-47.3095438182354\n",
      "Image:50 mean_a: 11.898582696914673 mean_b:-33.530373603105545\n",
      "Image:51 mean_a: 11.36802476644516 mean_b:-29.188559383153915\n",
      "Image:52 mean_a: 10.517250418663025 mean_b:-17.643585681915283\n",
      "Image:53 mean_a: 8.22103363275528 mean_b:-4.148070245981216\n",
      "Image:54 mean_a: 7.988850891590118 mean_b:-18.47824129462242\n",
      "Image:55 mean_a: 12.126190483570099 mean_b:-26.445106595754623\n",
      "Image:56 mean_a: 14.471743822097778 mean_b:-12.969958066940308\n",
      "Image:57 mean_a: 12.217400789260864 mean_b:-36.64010393619537\n",
      "Image:58 mean_a: 5.0570802092552185 mean_b:-3.90436652302742\n",
      "Image:59 mean_a: 15.08253824710846 mean_b:-61.45502197742462\n",
      "Image:60 mean_a: 16.449978470802307 mean_b:-26.37237849831581\n",
      "Image:61 mean_a: 12.890907049179077 mean_b:-42.76974502205849\n",
      "Image:62 mean_a: 12.96957802772522 mean_b:-31.95937830209732\n",
      "Image:63 mean_a: 11.703409969806671 mean_b:1.3250268697738647\n",
      "Image:64 mean_a: 13.255231499671936 mean_b:-9.172160655260086\n",
      "Image:65 mean_a: 10.956263661384583 mean_b:-6.65691602230072\n",
      "Image:66 mean_a: 10.792933225631714 mean_b:-26.757320642471313\n",
      "Image:67 mean_a: 13.853213012218475 mean_b:10.197581171989441\n",
      "Image:68 mean_a: 12.69784700870514 mean_b:-35.171399146318436\n",
      "Image:69 mean_a: 15.259365558624268 mean_b:-31.70609149336815\n",
      "Image:70 mean_a: 10.192367851734161 mean_b:-39.058499366045\n",
      "Image:71 mean_a: 11.758309423923492 mean_b:-36.403019458055496\n",
      "Image:72 mean_a: 9.841844260692596 mean_b:-9.497620791196823\n",
      "Image:73 mean_a: 13.857894361019135 mean_b:-20.726117074489594\n",
      "Image:74 mean_a: 16.160236418247223 mean_b:-2.61008757352829\n",
      "Image:75 mean_a: 10.436147570610046 mean_b:-14.628933846950531\n",
      "Image:76 mean_a: 13.08433187007904 mean_b:-25.585995495319366\n",
      "Image:77 mean_a: 9.168657183647156 mean_b:-35.97169700264931\n",
      "Image:78 mean_a: 10.784832060337067 mean_b:-37.73187655210495\n",
      "Image:79 mean_a: 13.12929105758667 mean_b:-64.2545445561409\n",
      "Image:80 mean_a: 11.910985231399536 mean_b:1.7778409719467163\n",
      "Image:81 mean_a: 11.43114697933197 mean_b:-36.20012554526329\n",
      "Image:82 mean_a: 15.97869735956192 mean_b:-57.53077495098114\n",
      "Image:83 mean_a: 16.191425144672394 mean_b:-37.89041164517403\n",
      "Image:84 mean_a: 12.307319164276123 mean_b:-27.190208613872528\n",
      "Image:85 mean_a: 15.838743269443512 mean_b:-35.86000579595566\n",
      "Image:86 mean_a: 10.135750889778137 mean_b:-76.69580656290054\n",
      "Image:87 mean_a: 15.351092636585236 mean_b:-28.05403146147728\n",
      "Image:88 mean_a: 9.090198993682861 mean_b:6.891332983970642\n",
      "Image:89 mean_a: 14.47286856174469 mean_b:-51.29208731651306\n",
      "Image:90 mean_a: 9.059192657470703 mean_b:-12.181743562221527\n",
      "Image:91 mean_a: 9.200742661952972 mean_b:-16.2706281542778\n",
      "Image:92 mean_a: 14.964911758899689 mean_b:-48.30241534113884\n",
      "Image:93 mean_a: 15.376855254173279 mean_b:-56.315220177173615\n",
      "Image:94 mean_a: 13.11732929944992 mean_b:-66.60477544367313\n",
      "Image:95 mean_a: 13.232478320598602 mean_b:-48.84697172045708\n",
      "Image:96 mean_a: 12.813923180103302 mean_b:3.8175867199897766\n",
      "Image:97 mean_a: 13.17651492357254 mean_b:-28.387600362300873\n",
      "Image:98 mean_a: 12.19331008195877 mean_b:-9.201289892196655\n",
      "Image:99 mean_a: 10.062034845352173 mean_b:-40.69984409213066\n",
      "Image:100 mean_a: 11.97722327709198 mean_b:-17.234834015369415\n",
      "Image:101 mean_a: 20.899144530296326 mean_b:-63.315592139959335\n",
      "Image:102 mean_a: 9.60715365409851 mean_b:-45.414957880973816\n",
      "Image:103 mean_a: 10.219726383686066 mean_b:-23.49939066171646\n",
      "Image:104 mean_a: 13.140462458133698 mean_b:-59.33801877498627\n",
      "Image:105 mean_a: 15.284185826778412 mean_b:-64.07036843895912\n",
      "Image:106 mean_a: 10.428760766983032 mean_b:-59.23394995927811\n",
      "Image:107 mean_a: 12.285173952579498 mean_b:-26.739894777536392\n",
      "Image:108 mean_a: 12.881255567073822 mean_b:-52.69146102666855\n",
      "Image:109 mean_a: 14.065545618534088 mean_b:-26.330998718738556\n",
      "Image:110 mean_a: 14.507157921791077 mean_b:-15.146914452314377\n",
      "Image:111 mean_a: 11.486472010612488 mean_b:-5.9041688144207\n",
      "Image:112 mean_a: 11.300631582736969 mean_b:-0.6409800350666046\n",
      "Image:113 mean_a: 10.765361905097961 mean_b:-19.658017188310623\n",
      "Image:114 mean_a: 17.304187834262848 mean_b:-32.20163810253143\n",
      "Image:115 mean_a: 13.23463660478592 mean_b:-26.30211266875267\n",
      "Image:116 mean_a: 12.54273933172226 mean_b:-39.38858765363693\n",
      "Image:117 mean_a: 15.161209225654602 mean_b:-42.80151891708374\n",
      "Image:118 mean_a: 12.758370161056519 mean_b:-34.2735453248024\n",
      "Image:119 mean_a: 16.249121248722076 mean_b:-17.548461586236954\n",
      "Image:120 mean_a: 11.565462172031403 mean_b:7.852088630199432\n",
      "Image:121 mean_a: 13.45766943693161 mean_b:-13.971158742904663\n",
      "Image:122 mean_a: 11.3032306432724 mean_b:-40.73584336042404\n",
      "Image:123 mean_a: 9.344314157962799 mean_b:-46.38277354836464\n",
      "Image:124 mean_a: 10.65501582622528 mean_b:-33.382683128118515\n",
      "Image:125 mean_a: 12.08804053068161 mean_b:-35.91662275791168\n",
      "Image:126 mean_a: 15.340696394443512 mean_b:-63.38377568125725\n",
      "Image:127 mean_a: 16.02546525001526 mean_b:-19.219596713781357\n",
      "Image:128 mean_a: 14.143806219100952 mean_b:-20.949659079313278\n",
      "Image:129 mean_a: 14.579794824123383 mean_b:-58.47796532511711\n",
      "Image:130 mean_a: 11.9085533618927 mean_b:-42.5317105948925\n",
      "Image:131 mean_a: 11.278547167778015 mean_b:-24.709937304258347\n",
      "Image:132 mean_a: 13.579430103302002 mean_b:-41.3193476498127\n",
      "Image:133 mean_a: 15.512857556343079 mean_b:-36.7824746966362\n",
      "Image:134 mean_a: 13.629465818405151 mean_b:-36.524073362350464\n",
      "Image:135 mean_a: 14.316803336143494 mean_b:-9.430881172418594\n",
      "Image:136 mean_a: 11.591255187988281 mean_b:-11.094127923250198\n",
      "Image:137 mean_a: 12.229332149028778 mean_b:-21.2758791744709\n",
      "Image:138 mean_a: 12.65876990556717 mean_b:-31.8207845389843\n",
      "Image:139 mean_a: 8.5558260679245 mean_b:-3.774063915014267\n",
      "Image:140 mean_a: 4.3749712109565735 mean_b:1.1495218873023987\n",
      "Image:141 mean_a: 22.024765729904175 mean_b:-46.87859374284744\n",
      "Image:142 mean_a: 12.445312559604645 mean_b:-47.00893434882164\n",
      "Image:143 mean_a: 14.573091983795166 mean_b:-39.274403780698776\n",
      "Image:144 mean_a: 18.11283004283905 mean_b:-64.99591517448425\n",
      "Image:145 mean_a: 13.87022089958191 mean_b:-20.003608644008636\n",
      "Image:146 mean_a: 14.886696755886078 mean_b:-24.81978940963745\n",
      "Image:147 mean_a: 14.202429473400116 mean_b:-7.244926869869232\n",
      "Image:148 mean_a: 9.10377186536789 mean_b:-10.215273082256317\n",
      "Image:149 mean_a: 12.705811381340027 mean_b:-1.2523900270462036\n",
      "Image:150 mean_a: 10.867363631725311 mean_b:-35.69273117184639\n",
      "Image:151 mean_a: 10.647826611995697 mean_b:-15.293685376644135\n",
      "Image:152 mean_a: 15.603976666927338 mean_b:-49.96094274520874\n",
      "Image:153 mean_a: 11.298640489578247 mean_b:-31.955137729644775\n",
      "Image:154 mean_a: 9.472200095653534 mean_b:-8.462677925825119\n",
      "Image:155 mean_a: 11.15827602148056 mean_b:3.0034728050231934\n",
      "Image:156 mean_a: 15.293031752109528 mean_b:22.990613102912903\n",
      "Image:157 mean_a: 9.347156405448914 mean_b:-59.62544295191765\n",
      "Image:158 mean_a: 9.251279950141907 mean_b:-13.78034058213234\n",
      "Image:159 mean_a: 11.329054057598114 mean_b:-25.62946516275406\n",
      "Image:160 mean_a: 9.27670818567276 mean_b:-6.039190769195557\n",
      "Image:161 mean_a: 10.672981262207031 mean_b:-42.53969016671181\n",
      "Image:162 mean_a: 12.736726522445679 mean_b:-28.016930252313614\n",
      "Image:163 mean_a: 14.829623818397522 mean_b:-51.58271852135658\n",
      "Image:164 mean_a: 13.248939037322998 mean_b:-22.414814859628677\n",
      "Image:165 mean_a: 14.25985199213028 mean_b:4.926154434680939\n",
      "Image:166 mean_a: 8.576420962810516 mean_b:-17.5348659157753\n",
      "Image:167 mean_a: 10.700400590896606 mean_b:-26.4506618976593\n",
      "Image:168 mean_a: 16.988789558410645 mean_b:-40.81021296977997\n",
      "Image:169 mean_a: 10.604098558425903 mean_b:-28.068569481372833\n",
      "Image:170 mean_a: 6.252268075942993 mean_b:-33.501715540885925\n",
      "Image:171 mean_a: 13.369909346103668 mean_b:-6.271525502204895\n",
      "Image:172 mean_a: 15.159871697425842 mean_b:-50.641577422618866\n",
      "Image:173 mean_a: 16.120323359966278 mean_b:-31.091755658388138\n",
      "Image:174 mean_a: 16.2281311750412 mean_b:-59.16056069731712\n",
      "Image:175 mean_a: 11.711191952228546 mean_b:-38.82099691033363\n",
      "Image:176 mean_a: 14.023337483406067 mean_b:-11.390823602676392\n",
      "Image:177 mean_a: 12.183521807193756 mean_b:-33.70495143532753\n",
      "Image:178 mean_a: 10.78440648317337 mean_b:-16.32373410463333\n",
      "Image:179 mean_a: 14.29993224143982 mean_b:-39.144952327013016\n",
      "Image:180 mean_a: 11.611804485321045 mean_b:-26.658244758844376\n",
      "Image:181 mean_a: 12.270673930644989 mean_b:-23.256553292274475\n",
      "Image:182 mean_a: 13.595267653465271 mean_b:-37.478012174367905\n",
      "Image:183 mean_a: 13.407451331615448 mean_b:0.7928122282028198\n",
      "Image:184 mean_a: 7.448337495326996 mean_b:-1.5016870498657227\n",
      "Image:185 mean_a: 12.518800616264343 mean_b:-58.13450175523758\n",
      "Image:186 mean_a: 8.983242332935333 mean_b:-16.691698759794235\n",
      "Image:187 mean_a: 12.635059177875519 mean_b:12.586391389369965\n",
      "Image:188 mean_a: 13.336319148540497 mean_b:-10.700499445199966\n",
      "Image:189 mean_a: 10.133303821086884 mean_b:-14.615292578935623\n",
      "Image:190 mean_a: 15.57076644897461 mean_b:-28.09423330426216\n",
      "Image:191 mean_a: 7.313262343406677 mean_b:-48.89050218462944\n",
      "Image:192 mean_a: 13.841388046741486 mean_b:-20.720181792974472\n",
      "Image:193 mean_a: 8.991769075393677 mean_b:-49.19015410542488\n",
      "Image:194 mean_a: 11.154780209064484 mean_b:-1.3073122799396515\n",
      "Image:195 mean_a: 6.727865755558014 mean_b:-14.909282803535461\n",
      "Image:196 mean_a: 14.677084803581238 mean_b:-51.077649623155594\n",
      "Image:197 mean_a: 10.996435105800629 mean_b:-47.856836050748825\n",
      "Image:198 mean_a: 12.459630191326141 mean_b:-8.709140300750732\n",
      "Image:199 mean_a: 11.644710719585419 mean_b:-56.64550605416298\n",
      "Image:200 mean_a: 15.368115723133087 mean_b:-19.540922671556473\n",
      "Image:201 mean_a: 9.97120451927185 mean_b:-9.836782991886139\n",
      "Image:202 mean_a: 14.175238132476807 mean_b:-10.102441936731339\n",
      "Image:203 mean_a: 7.652006566524506 mean_b:-26.522310853004456\n",
      "Image:204 mean_a: 11.103817343711853 mean_b:7.923433601856232\n",
      "Image:205 mean_a: 13.328597962856293 mean_b:-54.28740578889847\n",
      "Image:206 mean_a: 12.973955392837524 mean_b:-14.809051781892776\n",
      "Image:207 mean_a: 13.884584128856659 mean_b:-8.689487755298615\n",
      "Image:208 mean_a: 10.311134278774261 mean_b:-17.033384025096893\n",
      "Image:209 mean_a: 12.130233466625214 mean_b:-19.44775167107582\n",
      "Image:210 mean_a: 22.40628045797348 mean_b:-39.73931643366814\n"
     ]
    }
   ],
   "source": [
    "Myregressor.reg_test(augmented_batch_train,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Activation Function... tanh\n",
      "...colorizer training started...\n",
      "Epoch: 100, lr: 0.001, weight decay:1e-05\n",
      "epoch:0, loss:6.112061835825443\n",
      "epoch:1, loss:2.1533490461297333\n",
      "epoch:2, loss:1.752334319986403\n",
      "epoch:3, loss:1.5989542631432414\n",
      "epoch:4, loss:1.47391765890643\n",
      "epoch:5, loss:1.444797359406948\n",
      "epoch:6, loss:1.383231966290623\n",
      "epoch:7, loss:1.3290843437425792\n",
      "epoch:8, loss:1.3046284141018987\n",
      "epoch:9, loss:1.2716006133705378\n",
      "epoch:10, loss:1.2520246570929885\n",
      "epoch:11, loss:1.2163847675547004\n",
      "epoch:12, loss:1.2205568044446409\n",
      "epoch:13, loss:1.179863587487489\n",
      "epoch:14, loss:1.1724307178519666\n",
      "epoch:15, loss:1.154045583680272\n",
      "epoch:16, loss:1.1278316173702478\n",
      "epoch:17, loss:1.0997472321614623\n",
      "epoch:18, loss:1.1085330806672573\n",
      "epoch:19, loss:1.1050585876218975\n",
      "epoch:20, loss:1.0853676917031407\n",
      "epoch:21, loss:1.0704425824806094\n",
      "epoch:22, loss:1.0567525853402913\n",
      "epoch:23, loss:1.0614301685709506\n",
      "epoch:24, loss:1.0654945620335639\n",
      "epoch:25, loss:1.0530398939736187\n",
      "epoch:26, loss:1.0365573894232512\n",
      "epoch:27, loss:1.033095259219408\n",
      "epoch:28, loss:1.0369056547060609\n",
      "epoch:29, loss:1.0218769661150873\n",
      "epoch:30, loss:0.9945228218566626\n",
      "epoch:31, loss:1.0052204348612577\n",
      "epoch:32, loss:1.0056613099295646\n",
      "epoch:33, loss:1.0014978211838752\n",
      "epoch:34, loss:1.0024060187861323\n",
      "epoch:35, loss:0.9941595168784261\n",
      "epoch:36, loss:0.983256301144138\n",
      "epoch:37, loss:0.9798756658565253\n",
      "epoch:38, loss:0.9877044216264039\n",
      "epoch:39, loss:0.9845451156143099\n",
      "epoch:40, loss:0.9876125915907323\n",
      "epoch:41, loss:0.9688266760203987\n",
      "epoch:42, loss:0.9968213664833456\n",
      "epoch:43, loss:0.955903033958748\n",
      "epoch:44, loss:0.9670121816452593\n",
      "epoch:45, loss:0.9566105103585869\n",
      "epoch:46, loss:0.9718736556824297\n",
      "epoch:47, loss:0.9584992520976812\n",
      "epoch:48, loss:0.9664709756616503\n",
      "epoch:49, loss:0.9367076773196459\n",
      "epoch:50, loss:0.9410337449517101\n",
      "epoch:51, loss:0.9367488634306937\n",
      "epoch:52, loss:0.9372843892779201\n",
      "epoch:53, loss:0.9400568995624781\n",
      "epoch:54, loss:0.9326445939950645\n",
      "epoch:55, loss:0.9311666069552302\n",
      "epoch:56, loss:0.9349591308273375\n",
      "epoch:57, loss:0.9346758471801877\n",
      "epoch:58, loss:0.9292377217207104\n",
      "epoch:59, loss:0.9337440626695752\n",
      "epoch:60, loss:0.9416875562164932\n",
      "epoch:61, loss:0.9213548195548356\n",
      "epoch:62, loss:0.9262944026850164\n",
      "epoch:63, loss:0.9103458058089018\n",
      "epoch:64, loss:0.9380532861687243\n",
      "epoch:65, loss:0.9456696968991309\n",
      "epoch:66, loss:0.9098166842013597\n",
      "epoch:67, loss:0.9184579532593489\n",
      "epoch:68, loss:0.9286836683750153\n",
      "epoch:69, loss:0.9012722338084131\n",
      "epoch:70, loss:0.9145089429803193\n",
      "epoch:71, loss:0.9218979058787227\n",
      "epoch:72, loss:0.9010561460163444\n",
      "epoch:73, loss:0.914645099779591\n",
      "epoch:74, loss:0.9110745240468532\n",
      "epoch:75, loss:0.8998066687490791\n",
      "epoch:76, loss:0.9048544308170676\n",
      "epoch:77, loss:0.884699719492346\n",
      "epoch:78, loss:0.9021236747503281\n",
      "epoch:79, loss:0.9088993885088712\n",
      "epoch:80, loss:0.9076070038136095\n",
      "epoch:81, loss:0.9184248216915876\n",
      "epoch:82, loss:0.8914256042335182\n",
      "epoch:83, loss:0.8801909633912146\n",
      "epoch:84, loss:0.8743470043409616\n",
      "epoch:85, loss:0.8715687897056341\n",
      "epoch:86, loss:0.9043701954651624\n",
      "epoch:87, loss:0.8831403923686594\n",
      "epoch:88, loss:0.8793096179142594\n",
      "epoch:89, loss:0.8742936218623072\n",
      "epoch:90, loss:0.8923724738415331\n",
      "epoch:91, loss:0.8658961753826588\n",
      "epoch:92, loss:0.8777133652474731\n",
      "epoch:93, loss:0.8518682394642383\n",
      "epoch:94, loss:0.8923342055641115\n",
      "epoch:95, loss:0.8554842888843268\n",
      "epoch:96, loss:0.8500033661257476\n",
      "epoch:97, loss:0.8496114499866962\n",
      "epoch:98, loss:0.9589445444289595\n",
      "epoch:99, loss:0.8733904634136707\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"C:/Users/aashish/Desktop/DLCG2/Graphs/Colorizer/Colorizer_sigmoid_epoch{0}_lr_{1}_weight_decay_{2}.pth\"\n",
    "Myregressor.train_colorizer(augmented_batch_train, \"tanh\", model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, lr: 0.001, Weight_decay: 1e-05\n",
      "tanh\n",
      "--- Colorizer Testing Started ---\n",
      "Image: 1, loss: 0.011959073133766651\n",
      "Image: 2, loss: 0.00964464619755745\n",
      "Image: 3, loss: 0.012750282883644104\n",
      "Image: 4, loss: 0.006991264410316944\n",
      "Image: 5, loss: 0.009196768514811993\n",
      "Image: 6, loss: 0.021865447983145714\n",
      "Image: 7, loss: 0.00922407303005457\n",
      "Image: 8, loss: 0.013015315867960453\n",
      "Image: 9, loss: 0.011415302753448486\n",
      "Image: 10, loss: 0.012673464603722095\n",
      "Image: 11, loss: 0.01012748945504427\n",
      "Image: 12, loss: 0.017970463261008263\n",
      "Image: 13, loss: 0.010137038305401802\n",
      "Image: 14, loss: 0.008947424590587616\n",
      "Image: 15, loss: 0.008210793137550354\n",
      "Image: 16, loss: 0.006219716276973486\n",
      "Image: 17, loss: 0.014872046187520027\n",
      "Image: 18, loss: 0.009477346204221249\n",
      "Image: 19, loss: 0.009338989853858948\n",
      "Image: 20, loss: 0.014716923236846924\n",
      "Image: 21, loss: 0.011276190169155598\n",
      "Image: 22, loss: 0.03426972031593323\n",
      "Image: 23, loss: 0.013114918023347855\n",
      "Image: 24, loss: 0.006143219769001007\n",
      "Image: 25, loss: 0.007109323516488075\n",
      "Image: 26, loss: 0.013139275833964348\n",
      "Image: 27, loss: 0.005542196333408356\n",
      "Image: 28, loss: 0.007624181918799877\n",
      "Image: 29, loss: 0.0058363513089716434\n",
      "Image: 30, loss: 0.031327150762081146\n",
      "Image: 31, loss: 0.014805525541305542\n",
      "Image: 32, loss: 0.015492131933569908\n",
      "Image: 33, loss: 0.01128317229449749\n",
      "Image: 34, loss: 0.00928913988173008\n",
      "Image: 35, loss: 0.006258808076381683\n",
      "Image: 36, loss: 0.013336420990526676\n",
      "Image: 37, loss: 0.015369953587651253\n",
      "Image: 38, loss: 0.007670680060982704\n",
      "Image: 39, loss: 0.012797528877854347\n",
      "Image: 40, loss: 0.010685248300433159\n",
      "Image: 41, loss: 0.005862463265657425\n",
      "Image: 42, loss: 0.011875851079821587\n",
      "Image: 43, loss: 0.008571132086217403\n",
      "Image: 44, loss: 0.010581746697425842\n",
      "Image: 45, loss: 0.014290256425738335\n",
      "Image: 46, loss: 0.009439722634851933\n",
      "Image: 47, loss: 0.006980725564062595\n",
      "Image: 48, loss: 0.0055456263944506645\n",
      "Image: 49, loss: 0.024170110002160072\n",
      "Image: 50, loss: 0.008498507551848888\n",
      "Image: 51, loss: 0.008311496116220951\n",
      "Image: 52, loss: 0.012308286502957344\n",
      "Image: 53, loss: 0.013575240969657898\n",
      "Image: 54, loss: 0.02384309284389019\n",
      "Image: 55, loss: 0.020274806767702103\n",
      "Image: 56, loss: 0.02840430662035942\n",
      "Image: 57, loss: 0.012524919584393501\n",
      "Image: 58, loss: 0.008469810709357262\n",
      "Image: 59, loss: 0.0063333772122859955\n",
      "Image: 60, loss: 0.0066284602507948875\n",
      "Image: 61, loss: 0.005363465286791325\n",
      "Image: 62, loss: 0.006139085162431002\n",
      "Image: 63, loss: 0.006550537422299385\n",
      "Image: 64, loss: 0.016223600134253502\n",
      "Image: 65, loss: 0.012636722065508366\n",
      "Image: 66, loss: 0.01181175746023655\n",
      "Image: 67, loss: 0.01704941689968109\n",
      "Image: 68, loss: 0.00860909279435873\n",
      "Image: 69, loss: 0.006642508320510387\n",
      "Image: 70, loss: 0.005390885751694441\n",
      "Image: 71, loss: 0.008231831714510918\n",
      "Image: 72, loss: 0.009204991161823273\n",
      "Image: 73, loss: 0.008546576835215092\n",
      "Image: 74, loss: 0.015225820243358612\n",
      "Image: 75, loss: 0.014694638550281525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = {'grayscale': 'C:/Users/aashish/Desktop/DLCG2/Graphs/Colorizer/outputs/gray/', 'colorized': 'C:/Users/aashish/Desktop/DLCG2/Graphs/Colorizer/outputs/color/'}\n",
    "\n",
    "Myregressor.test_colorizer(augmented_batch_test, \"tanh\", save_path, model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_rgb(image):\n",
    "#     scale = random.uniform(0.6,1)\n",
    "#     scaled_rgb_image = image*scale\n",
    "#     return scaled_rgb_image\n",
    "\n",
    "# def flip():a\n",
    "#     return random.choice([True,False])\n",
    "\n",
    "# def augment_dataset(images, n):\n",
    "#     num_images = images.shape[0]\n",
    "#     augmented_data = torch.empty((n*num_images)+num_images, 3, 128, 128)\n",
    "    \n",
    "#     #random cropping\n",
    "#     crop = transforms.Compose([transforms.RandomResizedCrop(128,128)])\n",
    "#     horizontal_flip = transforms.Compose([transforms.RandomHorizontalFlip(p=.7)])\n",
    "    \n",
    "#     num = 0\n",
    "    \n",
    "#     #original training set\n",
    "#     for i in images:\n",
    "#         augmented_data[num] = torch.Tensor(np.array(image).astype(np.uint8))\n",
    "#         num+=1\n",
    "        \n",
    "#     for i in range(n):\n",
    "#         for image in images:\n",
    "#             if flip:\n",
    "#                 transformed_image = crop(image)\n",
    "#             transformed_image = horizontal_flip(image)\n",
    "#             transformed_image = scale_rgb(transformed_image)\n",
    "#             augmented_data[num] = torch.Tensor(np.array(transformed_image).astype(np.uint8))\n",
    "#             num+=1\n",
    "#     return augmented_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 : convert to LAB color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_LAB(images):\n",
    "#     num_images = images.shape[0]\n",
    "#     LAB_data = torch.empty(num_images,3,128,128)\n",
    "    \n",
    "#     images = images.permute(num_images, 3, 128, 128)\n",
    "#     for image in enumerate(images):\n",
    "#         image = np.array(image).astype(np.uint8)\n",
    "#         imageLAB = cv2.cvtColor(image, COLOR_RGB2LAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# class model():\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.layer1 = nn.Sequential(nn.Conv2d(1, 3, kernel_size=2, stride=2, padding=0), nn.ReLu())\n",
    "#         self.layer2 = nn.Sequential(nn.Conv2d(3, 3, kernel_size=2, stride=2, padding=0), nn.ReLu())\n",
    "#         self.layer3 = nn.Sequential(nn.Conv2d(3, 3, kernel_size=2, stride=2, padding=0), nn.ReLu())\n",
    "#         self.layer4 = nn.Sequential(nn.Conv2d(3, 3, kernel_size=2, stride=2, padding=0), nn.ReLu())\n",
    "#         self.layer5 = nn.Sequential(nn.Conv2d(3, 3, kernel_size=2, stride=2, padding=0), nn.ReLu())\n",
    "#         self.layer6 = nn.Sequential(nn.Conv2d(3, 3, kernel_size=2, stride=2, padding=0), nn.ReLu())\n",
    "#         self.layer7 = nn.Linear(2*2*3,2)\n",
    "#     def forward(self, X):\n",
    "#         X = self.layer1(X)\n",
    "#         X = self.layer2(X)\n",
    "#         X = self.layer3(X)\n",
    "#         X = self.layer4(X)\n",
    "#         X = self.layer5(X)\n",
    "#         X = self.layer6(X)\n",
    "#         tensor.reshape(X, (12,1))\n",
    "#         X = self.layer7(X)\n",
    "#         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABdata = []\n",
    "# for i in data:\n",
    "#     imageLAB = cv.cvtColor(i, cv.COLOR_BGR2LAB)\n",
    "#     LABdata.append(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
